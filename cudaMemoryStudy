regisiter：
for (int i = 0; i < size; ++i)
{
      sum += array[i];
}
如果sum不写在核函数里，而是在内存里，那么这个sum就要写size次，而如果当做局部变量，只是把最终结果写回到内存，则只进行一次读写，quickly！
int sum=0；
for (int i = 0; i < size; ++i)
      sum += array[i];
memSum=sum；//memSum是全局内存上的sum，只把最终结果写上去。把寄存器当做临时结果的存储。

Shared memory
https://blog.csdn.net/NYG8945/article/details/52874225?utm_source=blogxgwz3

cuda二维数组的创建与拷贝
https://blog.csdn.net/yu132563/article/details/52658080


全局内存机制：
    CUDA执行模型的特征之一指令都是以线程束为单位进行发布和执行，存储操作也是如此。全局内存是通过缓存进行加载？？？？？？什么叫内存通过缓存加载。
    数据从全局内存到SM（stream-multiprocessor）的传输，会进行cache，如果cache命中了，下一次的访问的耗时将大大减少。 每个SM都具有单独的L1 cache，
所有的SM共用一个L2 cache。 在计算能力2.x之前的设备，全局内存的访问会在L1\L2 cache上缓存；在计算能力3.x以上的设备，全局内存的访问只在L2 cache上缓存。
对于L1 cache，每次按照128字节进行缓存；对于L2 cache，每次按照32字节进行缓存。 这个128字节访问和32字节访问是需要设置吗？？？？？默认是哪个？？？？？？
__Idg（）函数好像可以强制32字节取。    
    注意：在Fermi架构的机器上，L1缓存是默认参与对全局的加载（即128字节）。后面的架构默认是不启用L1缓存的，如果要使用，使用编译指令：-Xptxas -dlcm=ca. 
禁用则使用-Xptxas -dlcm=cg。
    对于L1 cache，内存块大小支持32字节、64字节以及128字节，内存基于线程束来合并，分别表示线程束中每个线程以一个字节（1*32=32）、2字节（2*32=64）、4字节（4*32=128）
为单位读取数据。前提是，访问必须连续，并且访问的地址是以32字节对齐。
    合并访问的两个条件：1、对齐的内存，所以opencv的gpuMat是对齐内存块，方便合并的方式从CPU往GPU中传输，和从全局内存中往共享内存输。
                      2、每个线程以1,2,4字节的连续。 若一个线程读一个结构体x，y，z的数据，虽然结构体之间是连续的内存，但是每个线程需要的是12个字节，不是1、2、4了
    对于L2 cache，合并访存的字节减少为32字节，那么L2 cache相对L1 cache的好处？ 在非对齐访问、分散访问（非连续访问）的情况下，提高吞吐量（cache的带宽利用率）
    非对齐与非合并  https://blog.csdn.net/qq_17239003/article/details/79038333
    对于128字节加载，因为缓存是加载一批数据（此处128字节）不是只加载1个数据，所以非对齐方式访问，非对齐情况所需数据存在2个128上，要访问两次，对齐的话1次就够。
一次128字节的内存事物处理即可完成。 一次内存事务处理的时间？？？？？？？？？？？？？

共享内存
    共享内存带宽1.5T/S，全局内存190G/S（共享内存带宽更宽）；并且共享内存读取速度也快。
    但是可能有bank冲突：bank是共享内存分成的大小相等的存储器模块，可以同时被访问。所以对n个不同bank的访问可以同时进行，大大提高带宽。但前提就是同一个
warp中的线程不能访问一个bank，访问一个bank就会有bank冲突（特例就是warp所有线程都访问一个bank的同一数据，会广播，只需一次命令），所以，
同一个warp中访问的数据最好放不同bank。（看郭QQ收藏帖子）。
    在冲突最严重的情况下，速度会比全局显存还慢，但是如果 half-warp 的线程访问同一地址的时候，会产生一次广播，其速度反而没有下降。在不发生 bank conflict 
时，访问共享存储器的速度与寄存器相同。
    for (int i = thrIdY - halfWindow; i < thrIdY + halfWindow + 1; i++) {
			for (int j = thrIdX - halfWindow; j < thrIdX + halfWindow+1; j++) {
				a = imgA[i][j];  以前是这么写的，会慢，先用寄存器给行存下来，减少了访问共享内存数量
				b = imgB[i][j];
				meanA += a;
				meanB += b;
				varA += a*a;
				varB += b*b;
				integAxB += a*b;
			}
		}
    
    
    for (int i = thrIdY - halfWindow; i < thrIdY + halfWindow + 1; i++) {
			curRowA = imgA[i];
			curRowB = imgB[i];
			for (int j = thrIdX - halfWindow; j < thrIdX + halfWindow+1; j++) {
				a = curRowA[j];
				b = curRowB[j];
				meanA += a;
				meanB += b;
				varA += a*a;
				varB += b*b;
				integAxB += a*b;
			}
		}
    
    
常量内存
    适用于线程束内所有线程（不一定所有，大多数线程）访问相同数据。如果访问不同的数据可能效率会降低。解释如下：
    当常量内存将数据分配或广播到线程束中的每个线程时（注意，实际上硬件会将单次内存读取操作广播到半个线程束），广播能够在单个周期内发生，
因此这个特性是非常有用的。虽然当所有16个线程都读取相同地址时，这个功能可以极大提高性能，但当所有16个线程分别读取不同的地址时，它实际上会降低性能。
如果半个线程束中的所有16个线程需要访问常量内存中的不同数据，那么这个16次不同的读取操作会被串行化，从而需要16倍的时间来发出请求。但如果从全局内存中读取，
那么这些请求就会同时发出。这种情况下，从常量内存读取就会慢于从全局内存中读取。？？？？？？最多访问几个不同的数据会比全局内存快？？？
    
