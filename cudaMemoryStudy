regisiter：
for (int i = 0; i < size; ++i)
{
      sum += array[i];
}
如果sum不写在核函数里，而是在内存里，那么这个sum就要写size次，而如果当做局部变量，只是把最终结果写回到内存，则只进行一次读写，quickly！
int sum=0；
for (int i = 0; i < size; ++i)
      sum += array[i];
memSum=sum；//memSum是全局内存上的sum，只把最终结果写上去。把寄存器当做临时结果的存储。

Shared memory
https://blog.csdn.net/NYG8945/article/details/52874225?utm_source=blogxgwz3

cuda二维数组的创建与拷贝
https://blog.csdn.net/yu132563/article/details/52658080


全局内存机制：
    CUDA执行模型的特征之一指令都是以线程束为单位进行发布和执行，存储操作也是如此。全局内存是通过缓存进行加载？？？？？？什么叫内存通过缓存加载。
    数据从全局内存到SM（stream-multiprocessor）的传输，会进行cache，如果cache命中了，下一次的访问的耗时将大大减少。 每个SM都具有单独的L1 cache，
所有的SM共用一个L2 cache。 在计算能力2.x之前的设备，全局内存的访问会在L1\L2 cache上缓存；在计算能力3.x以上的设备，全局内存的访问只在L2 cache上缓存。
对于L1 cache，每次按照128字节进行缓存；对于L2 cache，每次按照32字节进行缓存。 这个128字节访问和32字节访问是需要设置吗？？？？？默认是哪个？？？？？？
    注意：在Fermi架构的机器上，L1缓存是默认参与对全局的加载。后面的架构默认是不启用L1缓存的，如果要使用，使用编译指令：-Xptxas -dlcm=ca. 
禁用则使用-Xptxas -dlcm=cg
    
    对于L1 cache，内存块大小支持32字节、64字节以及128字节，分别表示线程束中每个线程以一个字节（1*32=32）、2字节（2*32=64）、4字节（4*32=128）
为单位读取数据。前提是，访问必须连续，并且访问的地址是以32字节对齐。
    对于L2 cache，合并访存的字节减少为32字节，那么L2 cache相对L1 cache的好处？ 在非对齐访问、分散访问（非连续访问）的情况下，提高吞吐量（cache的带宽利用率）
    非对齐与非合并  https://blog.csdn.net/qq_17239003/article/details/79038333
    对于128字节加载，因为缓存是加载一批数据（此处128字节）不是只加载1个数据，所以非对齐方式访问，非对齐情况所需数据存在2个128上，要访问两次，对齐的话1次就够。
一次128字节的内存事物处理即可完成。 一次内存事务处理的时间？？？？？？？？？？？？？

共享内存
    共享内存带宽1.5T/S，全局内存190G/S，
